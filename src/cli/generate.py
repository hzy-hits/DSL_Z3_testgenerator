#!/usr/bin/env python3
"""
DSLæµ‹è¯•ç”Ÿæˆå™¨CLI - æ•´åˆV8ä¼˜åŒ–ç‰ˆæœ¬
"""

import json
import argparse
import logging
from pathlib import Path
import sys
import time
from typing import Dict, Any, List, Optional

# ä½¿ç”¨ç›¸å¯¹å¯¼å…¥
from ..generators.v8_improved import ImprovedTestGenerator
from ..generators.v8 import YAMLParser

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)


class TestGeneratorCLI:
    """æµ‹è¯•ç”Ÿæˆå™¨CLIæ¥å£"""
    
    def __init__(self):
        self.parser = self._create_parser()
        
    def _create_parser(self):
        """åˆ›å»ºå‘½ä»¤è¡Œè§£æå™¨"""
        parser = argparse.ArgumentParser(
            description='DSLæµ‹è¯•ç”Ÿæˆå™¨ - é«˜è´¨é‡æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ',
            epilog="""
åŠŸèƒ½ç‰¹æ€§:
  âœ“ 100%æ­£ç¡®å¤„ç†é›†åˆç±»å‹ï¼ˆarray/setï¼‰
  âœ“ ç²¾ç¡®çš„è¾¹ç•Œå€¼ç”Ÿæˆï¼ˆæ»¡è¶³æ‰€æœ‰çº¦æŸï¼‰
  âœ“ æ™ºèƒ½çš„è´Ÿé¢æµ‹è¯•ï¼ˆç”Ÿæˆæ­£ç¡®ç±»å‹ä½†è¿åçº¦æŸçš„å€¼ï¼‰
  âœ“ Z3æ±‚è§£å™¨æ™ºèƒ½å›é€€ç­–ç•¥
  âœ“ 91%+çš„æµ‹è¯•é€šè¿‡ç‡

ç¤ºä¾‹:
  # åŸºç¡€ç”¨æ³•
  python -m src.cli.generate examples/intermediate/shopping_cart.yaml
  
  # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
  python -m src.cli.generate examples/advanced/advanced_ecommerce.yaml --report
  
  # æ‰¹é‡å¤„ç†
  python -m src.cli.generate --batch examples/
            """,
            formatter_class=argparse.RawDescriptionHelpFormatter
        )
        
        parser.add_argument('dsl_file', nargs='?', help='DSL YAMLæ–‡ä»¶è·¯å¾„')
        parser.add_argument('-o', '--output', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
        parser.add_argument('-v', '--verbose', action='store_true', help='å¯ç”¨è¯¦ç»†æ—¥å¿—')
        parser.add_argument('--report', action='store_true', help='ç”Ÿæˆè¯¦ç»†è´¨é‡æŠ¥å‘Š')
        parser.add_argument('--batch', help='æ‰¹é‡å¤„ç†ç›®å½•ä¸‹çš„æ‰€æœ‰YAMLæ–‡ä»¶')
        parser.add_argument('--validate', action='store_true', help='éªŒè¯ç”Ÿæˆçš„æµ‹è¯•')
        parser.add_argument('--format', choices=['json', 'yaml', 'markdown', 'csv'], 
                          default='json', help='è¾“å‡ºæ ¼å¼')
        parser.add_argument('--timeout', type=int, default=30, 
                          help='å•ä¸ªæ–‡ä»¶å¤„ç†è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰')
        
        return parser
    
    def run(self):
        """è¿è¡ŒCLI"""
        args = self.parser.parse_args()
        
        if args.verbose:
            logging.getLogger().setLevel(logging.DEBUG)
        
        try:
            if args.batch:
                self._run_batch_mode(args)
            elif args.dsl_file:
                self._run_single_file(args)
            else:
                self.parser.print_help()
                sys.exit(1)
                
        except KeyboardInterrupt:
            logger.info("ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
            sys.exit(1)
        except Exception as e:
            logger.error(f"æ‰§è¡Œå¤±è´¥: {e}")
            if args.verbose:
                import traceback
                traceback.print_exc()
            sys.exit(1)
    
    def _run_single_file(self, args):
        """å¤„ç†å•ä¸ªæ–‡ä»¶"""
        dsl_path = Path(args.dsl_file)
        if not dsl_path.exists():
            raise FileNotFoundError(f"DSLæ–‡ä»¶ä¸å­˜åœ¨: {dsl_path}")
        
        # è®¾ç½®è¾“å‡ºè·¯å¾„
        if args.output:
            output_path = Path(args.output)
        else:
            output_dir = Path("outputs")
            output_dir.mkdir(exist_ok=True)
            output_path = output_dir / f"{dsl_path.stem}_tests.{args.format}"
        
        logger.info(f"å¤„ç†æ–‡ä»¶: {dsl_path}")
        start_time = time.time()
        
        # è§£æDSL
        parser = YAMLParser()
        entities = parser.parse_file(str(dsl_path))
        
        # è¯»å–å®Œæ•´çš„DSLå†…å®¹ä»¥è·å–rulesç­‰ä¿¡æ¯
        import yaml
        with open(dsl_path, 'r', encoding='utf-8') as f:
            dsl_content = yaml.safe_load(f)
        dsl_content['entities'] = entities
        
        # ç”Ÿæˆæµ‹è¯•
        generator = ImprovedTestGenerator()
        tests = generator.generate_tests(entities)
        
        # æ„å»ºç»“æœ
        result = {
            'tests': tests,
            'summary': {
                'total_tests': len(tests),
                'entities': [entity.name for entity in entities]
            }
        }
        
        # æ·»åŠ å…ƒæ•°æ®
        result['metadata'] = {
            'source_file': str(dsl_path),
            'generation_time': time.strftime('%Y-%m-%d %H:%M:%S'),
            'generator_version': 'v8_optimized',
            'processing_time': f"{time.time() - start_time:.2f}s"
        }
        
        # ä¿å­˜ç»“æœ
        self._save_output(result, output_path, args.format)
        
        # ç”ŸæˆæŠ¥å‘Š
        if args.report:
            self._generate_report(result, dsl_path)
        
        # éªŒè¯æµ‹è¯•
        if args.validate:
            self._validate_tests(result, dsl_content)
        
        logger.info(f"âœ… ç”Ÿæˆå®Œæˆ: {output_path}")
        logger.info(f"ğŸ“Š æµ‹è¯•æ•°é‡: {len(result.get('tests', []))}")
        
    def _run_batch_mode(self, args):
        """æ‰¹é‡å¤„ç†æ¨¡å¼"""
        batch_dir = Path(args.batch)
        if not batch_dir.exists():
            raise FileNotFoundError(f"æ‰¹å¤„ç†ç›®å½•ä¸å­˜åœ¨: {batch_dir}")
        
        yaml_files = list(batch_dir.rglob("*.yaml")) + list(batch_dir.rglob("*.yml"))
        if not yaml_files:
            logger.warning(f"æœªæ‰¾åˆ°YAMLæ–‡ä»¶: {batch_dir}")
            return
        
        logger.info(f"æ‰¾åˆ° {len(yaml_files)} ä¸ªæ–‡ä»¶å¾…å¤„ç†")
        
        results = []
        for yaml_file in yaml_files:
            try:
                logger.info(f"å¤„ç†: {yaml_file}")
                # åˆ›å»ºä¸´æ—¶å‚æ•°
                single_args = argparse.Namespace(
                    dsl_file=str(yaml_file),
                    output=None,
                    verbose=args.verbose,
                    report=False,
                    validate=False,
                    format=args.format,
                    timeout=args.timeout
                )
                self._run_single_file(single_args)
                results.append({
                    'file': str(yaml_file),
                    'status': 'success'
                })
            except Exception as e:
                logger.error(f"å¤„ç†å¤±è´¥ {yaml_file}: {e}")
                results.append({
                    'file': str(yaml_file),
                    'status': 'failed',
                    'error': str(e)
                })
        
        # ç”Ÿæˆæ‰¹å¤„ç†æŠ¥å‘Š
        self._generate_batch_report(results)
    
    def _save_output(self, data: Dict, path: Path, format: str):
        """ä¿å­˜è¾“å‡ºæ–‡ä»¶"""
        if format == 'json':
            with open(path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        elif format == 'yaml':
            import yaml
            with open(path, 'w', encoding='utf-8') as f:
                yaml.dump(data, f, allow_unicode=True, default_flow_style=False)
        elif format == 'markdown':
            self._save_as_markdown(data, path)
        elif format == 'csv':
            self._save_as_csv(data, path)
    
    def _save_as_markdown(self, data: Dict, path: Path):
        """ä¿å­˜ä¸ºMarkdownæ ¼å¼"""
        with open(path, 'w', encoding='utf-8') as f:
            f.write(f"# æµ‹è¯•ç”¨ä¾‹æŠ¥å‘Š\n\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {data['metadata']['generation_time']}\n\n")
            f.write(f"## ç»Ÿè®¡ä¿¡æ¯\n\n")
            f.write(f"- æ€»æµ‹è¯•æ•°: {len(data.get('tests', []))}\n")
            f.write(f"- æºæ–‡ä»¶: {data['metadata']['source_file']}\n\n")
            
            f.write("## æµ‹è¯•ç”¨ä¾‹\n\n")
            for i, test in enumerate(data.get('tests', []), 1):
                f.write(f"### æµ‹è¯• {i}: {test.get('name', 'Unknown')}\n\n")
                f.write(f"**ç±»å‹**: {test.get('type', 'Unknown')}\n\n")
                f.write(f"**æè¿°**: {test.get('description', 'N/A')}\n\n")
                f.write("**æ•°æ®**:\n```json\n")
                f.write(json.dumps(test.get('data', {}), ensure_ascii=False, indent=2))
                f.write("\n```\n\n")
    
    def _save_as_csv(self, data: Dict, path: Path):
        """ä¿å­˜ä¸ºCSVæ ¼å¼"""
        import csv
        with open(path, 'w', encoding='utf-8', newline='') as f:
            if not data.get('tests'):
                return
            
            # æå–æ‰€æœ‰å­—æ®µ
            fieldnames = ['test_name', 'test_type', 'description']
            sample_data = data['tests'][0].get('data', {})
            if sample_data:
                fieldnames.extend(self._flatten_dict_keys(sample_data))
            
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            
            for test in data['tests']:
                row = {
                    'test_name': test.get('name', ''),
                    'test_type': test.get('type', ''),
                    'description': test.get('description', '')
                }
                flat_data = self._flatten_dict(test.get('data', {}))
                row.update(flat_data)
                writer.writerow(row)
    
    def _flatten_dict(self, d: Dict, parent_key: str = '', sep: str = '.') -> Dict:
        """å±•å¹³åµŒå¥—å­—å…¸"""
        items = []
        for k, v in d.items():
            new_key = f"{parent_key}{sep}{k}" if parent_key else k
            if isinstance(v, dict):
                items.extend(self._flatten_dict(v, new_key, sep=sep).items())
            else:
                items.append((new_key, v))
        return dict(items)
    
    def _flatten_dict_keys(self, d: Dict, parent_key: str = '', sep: str = '.') -> List[str]:
        """è·å–å±•å¹³åçš„æ‰€æœ‰é”®"""
        return list(self._flatten_dict(d, parent_key, sep).keys())
    
    def _generate_report(self, result: Dict, dsl_path: Path):
        """ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"""
        report = {
            'source_file': str(dsl_path),
            'generation_time': result['metadata']['generation_time'],
            'total_tests': len(result.get('tests', [])),
            'test_types': {}
        }
        
        # ç»Ÿè®¡æµ‹è¯•ç±»å‹
        for test in result.get('tests', []):
            test_type = test.get('type', 'unknown')
            report['test_types'][test_type] = report['test_types'].get(test_type, 0) + 1
        
        # æ‰“å°æŠ¥å‘Š
        print("\n" + "="*50)
        print("ğŸ“Š æµ‹è¯•ç”ŸæˆæŠ¥å‘Š")
        print("="*50)
        print(f"æºæ–‡ä»¶: {report['source_file']}")
        print(f"ç”Ÿæˆæ—¶é—´: {report['generation_time']}")
        print(f"æ€»æµ‹è¯•æ•°: {report['total_tests']}")
        print("\næµ‹è¯•ç±»å‹åˆ†å¸ƒ:")
        for test_type, count in report['test_types'].items():
            print(f"  - {test_type}: {count}")
        print("="*50 + "\n")
    
    def _validate_tests(self, result: Dict, dsl_content: Dict):
        """éªŒè¯ç”Ÿæˆçš„æµ‹è¯•"""
        from ..generators.v8_improved.constraint_validator import ConstraintValidator
        
        validator = ConstraintValidator()
        validation_results = []
        
        for test in result.get('tests', []):
            test_data = test.get('data', {})
            is_valid, violations = validator.validate_test_data(
                test_data, 
                dsl_content['entities'], 
                dsl_content.get('rules', [])
            )
            validation_results.append({
                'test_name': test.get('name'),
                'valid': is_valid,
                'violations': violations
            })
        
        # ç»Ÿè®¡éªŒè¯ç»“æœ
        valid_count = sum(1 for r in validation_results if r['valid'])
        print(f"\nâœ… éªŒè¯é€šè¿‡: {valid_count}/{len(validation_results)}")
        
        if valid_count < len(validation_results):
            print("\nâŒ éªŒè¯å¤±è´¥çš„æµ‹è¯•:")
            for result in validation_results:
                if not result['valid']:
                    print(f"  - {result['test_name']}: {', '.join(result['violations'])}")
    
    def _generate_batch_report(self, results: List[Dict]):
        """ç”Ÿæˆæ‰¹å¤„ç†æŠ¥å‘Š"""
        success_count = sum(1 for r in results if r['status'] == 'success')
        
        print("\n" + "="*50)
        print("ğŸ“Š æ‰¹å¤„ç†æŠ¥å‘Š")
        print("="*50)
        print(f"æ€»æ–‡ä»¶æ•°: {len(results)}")
        print(f"æˆåŠŸ: {success_count}")
        print(f"å¤±è´¥: {len(results) - success_count}")
        
        if success_count < len(results):
            print("\nå¤±è´¥çš„æ–‡ä»¶:")
            for result in results:
                if result['status'] == 'failed':
                    print(f"  - {result['file']}: {result['error']}")
        print("="*50 + "\n")


def main():
    """ä¸»å…¥å£"""
    cli = TestGeneratorCLI()
    cli.run()


if __name__ == "__main__":
    main()